package database

import (
	"fmt"
	"math/rand"
	"os"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/cloudboot/cloudboot-ng/internal/models"
	"github.com/google/uuid"
	"gorm.io/gorm"
	"gorm.io/gorm/logger"
)

// BenchmarkResult å‹æµ‹ç»“æœ
type BenchmarkResult struct {
	TotalOps       int           // æ€»æ“ä½œæ•°
	SuccessOps     int           // æˆåŠŸæ“ä½œæ•°
	FailedOps      int           // å¤±è´¥æ“ä½œæ•°
	Duration       time.Duration // æ€»è€—æ—¶
	OpsPerSecond   float64       // æ¯ç§’æ“ä½œæ•°
	AvgLatency     time.Duration // å¹³å‡å»¶è¿Ÿ
	MaxLatency     time.Duration // æœ€å¤§å»¶è¿Ÿ
	MinLatency     time.Duration // æœ€å°å»¶è¿Ÿ
	ConcurrentGR   int           // å¹¶å‘æ•°
	WALModeEnabled bool          // WALæ¨¡å¼æ˜¯å¦å¯ç”¨
}

// TestConcurrentWrites æµ‹è¯•å¹¶å‘å†™å…¥
func TestConcurrentWrites(t *testing.T) {
	// åˆ›å»ºæµ‹è¯•æ•°æ®åº“
	db := setupTestDB(t)
	defer cleanupTestDB(t, db)

	concurrentGoroutines := []int{1, 10, 50, 100}

	for _, concurrent := range concurrentGoroutines {
		t.Run(fmt.Sprintf("Concurrent_%d", concurrent), func(t *testing.T) {
			result := benchmarkConcurrentWrites(t, db, concurrent, 100)

			t.Logf("ğŸ“Š å¹¶å‘å†™å…¥æµ‹è¯•ç»“æœ (å¹¶å‘æ•°: %d)", concurrent)
			t.Logf("   - æ€»æ“ä½œæ•°: %d", result.TotalOps)
			t.Logf("   - æˆåŠŸæ“ä½œ: %d", result.SuccessOps)
			t.Logf("   - å¤±è´¥æ“ä½œ: %d", result.FailedOps)
			t.Logf("   - æ€»è€—æ—¶: %v", result.Duration)
			t.Logf("   - TPS: %.2f ops/s", result.OpsPerSecond)
			t.Logf("   - å¹³å‡å»¶è¿Ÿ: %v", result.AvgLatency)
			t.Logf("   - æœ€å¤§å»¶è¿Ÿ: %v", result.MaxLatency)
			t.Logf("   - WALæ¨¡å¼: %v", result.WALModeEnabled)

			// æ€§èƒ½åŸºå‡†æ£€æŸ¥
			if result.OpsPerSecond < 100 {
				t.Errorf("âš ï¸  TPS too low: %.2f < 100", result.OpsPerSecond)
			} else {
				t.Logf("âœ… TPS acceptable: %.2f ops/s", result.OpsPerSecond)
			}

			// å¤±è´¥ç‡æ£€æŸ¥
			failureRate := float64(result.FailedOps) / float64(result.TotalOps) * 100
			if failureRate > 5.0 {
				t.Errorf("âš ï¸  Failure rate too high: %.2f%%", failureRate)
			} else {
				t.Logf("âœ… Failure rate acceptable: %.2f%%", failureRate)
			}
		})
	}
}

// TestConcurrentReads æµ‹è¯•å¹¶å‘è¯»å–
func TestConcurrentReads(t *testing.T) {
	db := setupTestDB(t)
	defer cleanupTestDB(t, db)

	// å…ˆæ’å…¥æµ‹è¯•æ•°æ®
	prepareTestData(t, db, 1000)

	concurrentGoroutines := []int{10, 50, 100, 200}

	for _, concurrent := range concurrentGoroutines {
		t.Run(fmt.Sprintf("Concurrent_%d", concurrent), func(t *testing.T) {
			result := benchmarkConcurrentReads(t, db, concurrent, 100)

			t.Logf("ğŸ“Š å¹¶å‘è¯»å–æµ‹è¯•ç»“æœ (å¹¶å‘æ•°: %d)", concurrent)
			t.Logf("   - TPS: %.2f ops/s", result.OpsPerSecond)
			t.Logf("   - å¹³å‡å»¶è¿Ÿ: %v", result.AvgLatency)
			t.Logf("   - æœ€å¤§å»¶è¿Ÿ: %v", result.MaxLatency)

			// è¯»å–æ€§èƒ½åº”è¯¥æ›´é«˜
			if result.OpsPerSecond < 500 {
				t.Logf("âš ï¸  Read TPS: %.2f (could be improved)", result.OpsPerSecond)
			} else {
				t.Logf("âœ… Read TPS excellent: %.2f ops/s", result.OpsPerSecond)
			}
		})
	}
}

// TestMixedReadWrite æµ‹è¯•æ··åˆè¯»å†™
func TestMixedReadWrite(t *testing.T) {
	db := setupTestDB(t)
	defer cleanupTestDB(t, db)

	// å‡†å¤‡åˆå§‹æ•°æ®
	prepareTestData(t, db, 100)

	// 80% è¯»å–, 20% å†™å…¥ï¼ˆçœŸå®åœºæ™¯ï¼‰
	result := benchmarkMixedReadWrite(t, db, 50, 1000, 0.2)

	t.Logf("ğŸ“Š æ··åˆè¯»å†™æµ‹è¯•ç»“æœ")
	t.Logf("   - æ€»æ“ä½œæ•°: %d", result.TotalOps)
	t.Logf("   - TPS: %.2f ops/s", result.OpsPerSecond)
	t.Logf("   - å¹³å‡å»¶è¿Ÿ: %v", result.AvgLatency)
	t.Logf("   - WALæ¨¡å¼: %v", result.WALModeEnabled)

	if result.FailedOps > 0 {
		t.Logf("âš ï¸  Failed operations: %d", result.FailedOps)
	} else {
		t.Log("âœ… No failed operations")
	}
}

// TestWALMode éªŒè¯WALæ¨¡å¼
func TestWALMode(t *testing.T) {
	db := setupTestDB(t)
	defer cleanupTestDB(t, db)

	// æ£€æŸ¥journal_mode
	var journalMode string
	sqlDB, _ := db.DB()
	row := sqlDB.QueryRow("PRAGMA journal_mode")
	row.Scan(&journalMode)

	t.Logf("ğŸ“‹ Journal Mode: %s", journalMode)

	if journalMode != "wal" {
		t.Errorf("âŒ WAL mode not enabled: %s", journalMode)
	} else {
		t.Log("âœ… WAL mode enabled")
	}

	// æ£€æŸ¥WALç›¸å…³é…ç½®
	var walAutocheckpoint int
	sqlDB.QueryRow("PRAGMA wal_autocheckpoint").Scan(&walAutocheckpoint)
	t.Logf("   - WAL autocheckpoint: %d", walAutocheckpoint)

	var synchronous string
	sqlDB.QueryRow("PRAGMA synchronous").Scan(&synchronous)
	t.Logf("   - Synchronous mode: %s", synchronous)
}

// TestStressTest å‹åŠ›æµ‹è¯•ï¼šæ¨¡æ‹Ÿ100ä¸ªAgentåŒæ—¶æ³¨å†Œ
func TestStressTest(t *testing.T) {
	if testing.Short() {
		t.Skip("è·³è¿‡å‹åŠ›æµ‹è¯• (ä½¿ç”¨ -short æ ‡å¿—)")
	}

	db := setupTestDB(t)
	defer cleanupTestDB(t, db)

	t.Log("ğŸ”¥ å‹åŠ›æµ‹è¯•: 100ä¸ªå¹¶å‘Agentï¼Œæ¯ä¸ªAgentæ³¨å†Œ10æ¬¡")

	result := benchmarkConcurrentWrites(t, db, 100, 10)

	t.Logf("ğŸ“Š å‹åŠ›æµ‹è¯•ç»“æœ")
	t.Logf("   - æ€»Machineæ³¨å†Œæ•°: %d", result.TotalOps)
	t.Logf("   - æˆåŠŸ: %d", result.SuccessOps)
	t.Logf("   - å¤±è´¥: %d", result.FailedOps)
	t.Logf("   - æ€»è€—æ—¶: %v", result.Duration)
	t.Logf("   - TPS: %.2f ops/s", result.OpsPerSecond)
	t.Logf("   - å¹³å‡å»¶è¿Ÿ: %v", result.AvgLatency)
	t.Logf("   - æœ€å¤§å»¶è¿Ÿ: %v", result.MaxLatency)

	// å‹åŠ›æµ‹è¯•åŸºå‡†
	if result.FailedOps > result.TotalOps/10 {
		t.Errorf("âŒ Too many failures: %d/%d", result.FailedOps, result.TotalOps)
	}

	if result.OpsPerSecond < 50 {
		t.Logf("âš ï¸  Low TPS under stress: %.2f", result.OpsPerSecond)
	} else {
		t.Logf("âœ… Acceptable TPS under stress: %.2f", result.OpsPerSecond)
	}
}

// benchmarkConcurrentWrites å¹¶å‘å†™å…¥åŸºå‡†æµ‹è¯•
func benchmarkConcurrentWrites(t *testing.T, db *gorm.DB, concurrent int, opsPerGoroutine int) *BenchmarkResult {
	var wg sync.WaitGroup
	var mu sync.Mutex
	var atomicCounter int64 // åŸå­è®¡æ•°å™¨ç¡®ä¿å”¯ä¸€æ€§

	totalOps := concurrent * opsPerGoroutine
	successCount := 0
	failedCount := 0
	latencies := make([]time.Duration, 0, totalOps)
	errors := make(map[string]int) // è®°å½•é”™è¯¯ç±»å‹

	startTime := time.Now()

	for i := 0; i < concurrent; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for j := 0; j < opsPerGoroutine; j++ {
				// ä½¿ç”¨åŸå­è®¡æ•°å™¨ç¡®ä¿å”¯ä¸€æ€§
				counter := atomicInc(&atomicCounter)
				machineID := uuid.New().String()

				machine := &models.Machine{
					ID:         machineID,
					Hostname:   fmt.Sprintf("stress-%s", machineID[:8]),
					MacAddress: fmt.Sprintf("02:%02x:%02x:%02x:%02x:%02x",
						(counter>>24)&0xFF, (counter>>16)&0xFF, (counter>>8)&0xFF, counter&0xFF, workerID),
					IPAddress:  fmt.Sprintf("10.%d.%d.%d", (counter>>16)&0xFF, (counter>>8)&0xFF, counter&0xFF),
					Status:     "ready",
				}

				opStart := time.Now()
				err := db.Create(machine).Error
				latency := time.Since(opStart)

				mu.Lock()
				latencies = append(latencies, latency)
				if err != nil {
					failedCount++
					errors[err.Error()]++
					if failedCount <= 5 { // åªæ‰“å°å‰5ä¸ªé”™è¯¯
						t.Logf("âŒ Write error: %v", err)
					}
				} else {
					successCount++
				}
				mu.Unlock()
			}
		}(i)
	}

	wg.Wait()
	duration := time.Since(startTime)

	// æ‰“å°é”™è¯¯ç»Ÿè®¡
	if len(errors) > 0 {
		t.Logf("ğŸ“‹ Error types:")
		for errMsg, count := range errors {
			t.Logf("   - %s: %d times", errMsg, count)
		}
	}

	return &BenchmarkResult{
		TotalOps:       totalOps,
		SuccessOps:     successCount,
		FailedOps:      failedCount,
		Duration:       duration,
		OpsPerSecond:   float64(totalOps) / duration.Seconds(),
		AvgLatency:     calculateAvg(latencies),
		MaxLatency:     calculateMax(latencies),
		MinLatency:     calculateMin(latencies),
		ConcurrentGR:   concurrent,
		WALModeEnabled: checkWALMode(db),
	}
}

// benchmarkConcurrentReads å¹¶å‘è¯»å–åŸºå‡†æµ‹è¯•
func benchmarkConcurrentReads(t *testing.T, db *gorm.DB, concurrent int, opsPerGoroutine int) *BenchmarkResult {
	var wg sync.WaitGroup
	var mu sync.Mutex

	totalOps := concurrent * opsPerGoroutine
	successCount := 0
	failedCount := 0
	latencies := make([]time.Duration, 0, totalOps)

	startTime := time.Now()

	for i := 0; i < concurrent; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()

			for j := 0; j < opsPerGoroutine; j++ {
				var machines []models.Machine

				opStart := time.Now()
				err := db.Limit(10).Find(&machines).Error
				latency := time.Since(opStart)

				mu.Lock()
				latencies = append(latencies, latency)
				if err != nil {
					failedCount++
				} else {
					successCount++
				}
				mu.Unlock()
			}
		}()
	}

	wg.Wait()
	duration := time.Since(startTime)

	return &BenchmarkResult{
		TotalOps:       totalOps,
		SuccessOps:     successCount,
		FailedOps:      failedCount,
		Duration:       duration,
		OpsPerSecond:   float64(totalOps) / duration.Seconds(),
		AvgLatency:     calculateAvg(latencies),
		MaxLatency:     calculateMax(latencies),
		MinLatency:     calculateMin(latencies),
		ConcurrentGR:   concurrent,
		WALModeEnabled: checkWALMode(db),
	}
}

// benchmarkMixedReadWrite æ··åˆè¯»å†™åŸºå‡†æµ‹è¯•
func benchmarkMixedReadWrite(t *testing.T, db *gorm.DB, concurrent int, totalOps int, writeRatio float64) *BenchmarkResult {
	var wg sync.WaitGroup
	var mu sync.Mutex
	var atomicCounter int64

	successCount := 0
	failedCount := 0
	latencies := make([]time.Duration, 0, totalOps)
	opsPerGoroutine := totalOps / concurrent

	startTime := time.Now()

	for i := 0; i < concurrent; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for j := 0; j < opsPerGoroutine; j++ {
				var err error
				opStart := time.Now()

				// æ ¹æ®writeRatioå†³å®šæ˜¯è¯»è¿˜æ˜¯å†™
				if rand.Float64() < writeRatio {
					// å†™æ“ä½œ - ä½¿ç”¨åŸå­è®¡æ•°å™¨ç¡®ä¿å”¯ä¸€æ€§
					counter := atomicInc(&atomicCounter)
					machineID := uuid.New().String()
					machine := &models.Machine{
						ID:       machineID,
						Hostname: fmt.Sprintf("mixed-%s", machineID[:8]),
						MacAddress: fmt.Sprintf("02:%02x:%02x:%02x:%02x:%02x",
							(counter>>24)&0xFF, (counter>>16)&0xFF, (counter>>8)&0xFF, counter&0xFF, workerID),
						IPAddress: fmt.Sprintf("192.168.%d.%d", (counter>>8)&0xFF, counter&0xFF),
						Status:    "ready",
					}
					err = db.Create(machine).Error
				} else {
					// è¯»æ“ä½œ
					var machines []models.Machine
					err = db.Limit(10).Find(&machines).Error
				}

				latency := time.Since(opStart)

				mu.Lock()
				latencies = append(latencies, latency)
				if err != nil {
					failedCount++
				} else {
					successCount++
				}
				mu.Unlock()
			}
		}(i)
	}

	wg.Wait()
	duration := time.Since(startTime)

	return &BenchmarkResult{
		TotalOps:       totalOps,
		SuccessOps:     successCount,
		FailedOps:      failedCount,
		Duration:       duration,
		OpsPerSecond:   float64(totalOps) / duration.Seconds(),
		AvgLatency:     calculateAvg(latencies),
		MaxLatency:     calculateMax(latencies),
		MinLatency:     calculateMin(latencies),
		ConcurrentGR:   concurrent,
		WALModeEnabled: checkWALMode(db),
	}
}

// Helper functions

func setupTestDB(t *testing.T) *gorm.DB {
	// ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶æ•°æ®åº“ä»¥æ”¯æŒWALæ¨¡å¼
	dbPath := fmt.Sprintf("/tmp/cloudboot-bench-%d.db", time.Now().UnixNano())
	config := Config{
		DSN:      dbPath + "?_journal_mode=WAL",
		LogLevel: logger.Silent,
	}

	err := Init(config)
	if err != nil {
		t.Fatalf("failed to setup test db: %v", err)
	}

	// æ¸…ç†å‡½æ•°ä¼šåœ¨æµ‹è¯•ç»“æŸæ—¶åˆ é™¤æ•°æ®åº“æ–‡ä»¶
	t.Cleanup(func() {
		Close()
		// åˆ é™¤ä¸´æ—¶æ•°æ®åº“æ–‡ä»¶
		os.Remove(dbPath)
		os.Remove(dbPath + "-shm")
		os.Remove(dbPath + "-wal")
	})

	return DB
}

func cleanupTestDB(t *testing.T, db *gorm.DB) {
	Close()
}

func prepareTestData(t *testing.T, db *gorm.DB, count int) {
	for i := 0; i < count; i++ {
		machine := &models.Machine{
			ID:         uuid.New().String(),
			Hostname:   fmt.Sprintf("test-machine-%d", i),
			MacAddress: fmt.Sprintf("00:00:00:00:%02x:%02x", i/256, i%256),
			IPAddress:  fmt.Sprintf("10.0.%d.%d", i/256, i%256),
			Status:     "ready",
		}
		db.Create(machine)
	}
	t.Logf("âœ… Prepared %d test machines", count)
}

func checkWALMode(db *gorm.DB) bool {
	var journalMode string
	sqlDB, _ := db.DB()
	sqlDB.QueryRow("PRAGMA journal_mode").Scan(&journalMode)
	return journalMode == "wal"
}

func calculateAvg(latencies []time.Duration) time.Duration {
	if len(latencies) == 0 {
		return 0
	}
	var total time.Duration
	for _, l := range latencies {
		total += l
	}
	return total / time.Duration(len(latencies))
}

func calculateMax(latencies []time.Duration) time.Duration {
	if len(latencies) == 0 {
		return 0
	}
	max := latencies[0]
	for _, l := range latencies {
		if l > max {
			max = l
		}
	}
	return max
}

func calculateMin(latencies []time.Duration) time.Duration {
	if len(latencies) == 0 {
		return 0
	}
	min := latencies[0]
	for _, l := range latencies {
		if l < min {
			min = l
		}
	}
	return min
}

// atomicInc åŸå­é€’å¢è®¡æ•°å™¨
func atomicInc(counter *int64) int64 {
	return atomic.AddInt64(counter, 1)
}
